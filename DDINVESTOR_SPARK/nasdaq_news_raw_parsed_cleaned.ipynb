{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "''\n",
    "sc = pyspark.SparkContext(appName=\"nasdaq_news_raw_parsed_cleaned\")\n",
    "spark = SparkSession(sc)\n",
    "spark.conf.set('spark.sql.session.timeZone', 'UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skainet_spark import Pipeline, transform, Input, Output, Metadata,ValidatedPipeline,assign_shortcuts,print_statistics\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType,DoubleType,ArrayType,FloatType, BooleanType,IntegerType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasdaq News Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform(spark,\n",
    "    raw = Output('/nasdaq_news/raw/nasdaq_news_raw.parquet'),\n",
    "    metadata = Metadata('/nasdaq_news/raw/nasdaq_news_metadata_raw.csv', spark)\n",
    ")\n",
    "def raw_nasdaq_news(spark,raw,metadata):\n",
    "    schema=metadata()\n",
    "    df = (spark\n",
    "          .read\n",
    "          .format('json')\n",
    "          \n",
    "          .schema(schema)\n",
    "          .load('input/nasdaq_news/*.json')\n",
    "         )\n",
    "    pipeline=Pipeline(df)\n",
    "    pipeline.show_dimensions()\n",
    "    pipeline.dataframe.show(10)\n",
    "    pipeline.write(raw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cols: 5 rows: 1668\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               title|             content|         contributor|      published_date|   mentioned_tickers|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|\n",
      "3M Co (MMM) Q1 2...|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Image source...|\n",
      "Publisher\n",
      "\n",
      "\n",
      "The ...|2019-04-25T15:00:...|             [\"MMM\"]|\n",
      "|\n",
      "3M Co (MMM) Q2 2...|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Image source...|\n",
      "Publisher\n",
      "\n",
      "\n",
      "The ...|2019-07-25T19:23:...|             [\"MMM\"]|\n",
      "|\n",
      "3M (MMM) Q3 2017...|\n",
      "\n",
      "\n",
      "\n",
      "Image source:...|\n",
      "Publisher\n",
      "\n",
      "\n",
      "The ...|2017-10-25T12:54:...|             [\"MMM\"]|\n",
      "|\n",
      "3M (MMM) Q4 2018...|\n",
      "\n",
      "\n",
      "\n",
      "Image source:...|\n",
      "Publisher\n",
      "\n",
      "\n",
      "The ...|2019-01-29T09:52:...|             [\"MMM\"]|\n",
      "|\n",
      "3M Co (MMM) Q4 2...|\n",
      "Image source: Th...|\n",
      "Contributor\n",
      "\n",
      "\n",
      "  ...|2020-01-28T14:30:...|             [\"MMM\"]|\n",
      "|\n",
      "3M Co (MMM) Q3 2...|\n",
      "\n",
      "\n",
      "\n",
      "Image source:...|\n",
      "Publisher\n",
      "\n",
      "\n",
      "The ...|2018-10-23T03:42:...|             [\"MMM\"]|\n",
      "|\n",
      "3M Co (MMM) Q1 2...|\n",
      "Image source: Th...|\n",
      "Contributor\n",
      "\n",
      "\n",
      "  ...|2020-04-28T13:30:...|             [\"MMM\"]|\n",
      "|\n",
      "How to Be a Bett...|\n",
      "In this episode ...|\n",
      "Contributor\n",
      "\n",
      "\n",
      "  ...|2020-05-30T12:25:...|[\"BRK.A\",\"BRK.B\",...|\n",
      "|\n",
      "How Are Market C...|\n",
      "This is the nint...|Contributor Motle...|2020-03-25T15:18:...|[\"AAPL\",\"GOOGL\",\"...|\n",
      "|\n",
      "Three Takeaways ...|\n",
      "We are in the th...|\n",
      "Publisher\n",
      "\n",
      "\n",
      "Zack...|2017-10-20T04:25:...|[\"MMM\",\"MSFT\",\"UP...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_nasdaq_news(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasdaq News Parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform(spark,\n",
    "    raw = Input('/nasdaq_news/raw/nasdaq_news_raw.parquet',spark),\n",
    "    parsed = Output('/nasdaq_news/parsed/nasdaq_news_parsed.parquet')\n",
    ")\n",
    "def parsed_nasdaq_news(spark,raw,parsed):\n",
    "    pipe = Pipeline(raw)\n",
    "    print_statistics(pipe)\n",
    "    \n",
    "    cols_rename = {\n",
    "        'contributor':'publisher'\n",
    "    }\n",
    "    pipe = (pipe\n",
    "            .rename_columns(cols_rename)\n",
    "            .transform(parse_delete_chars,'publisher')\n",
    "            .transform(parse_delete_chars,'title')\n",
    "            .transform(parse_content)\n",
    "\n",
    "            #.transform(extract_news_writers)\n",
    "            .transform(parse_contributor)\n",
    "            .transform(parse_date)\n",
    "            .transform(parse_mentioned_tickers)\n",
    "            .transform(drop_records_null_content)\n",
    "            \n",
    "           )\n",
    "    #pipe.dataframe.groupby('contributor').count().show(1000,0)\n",
    "    pipe.dataframe.select('published_date','title').where(F.col('publisher').contains('InvestorPlace')).show(2,0)\n",
    "    \n",
    "    print('Nasdaq News')\n",
    "    print_statistics(pipe)\n",
    "    pipe.write(parsed)\n",
    "    \n",
    "def drop_records_null_content(dataframe):\n",
    "    col = 'content'\n",
    "    dataframe = dataframe.where(F.col(col).isNotNull())\n",
    "    return dataframe\n",
    "    \n",
    "def parse_content(dataframe):\n",
    "    col='content'\n",
    "    constant_suffix = \"\"\"\\nThe views and opinions expressed herein are the views and opinions of the author and do not necessarily reflect those of Nasdaq, Inc.\\n\"\"\"\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),constant_suffix,''))\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),\"<(?s).*>\",' '))\n",
    "    dataframe = parse_delete_chars(dataframe,col)\n",
    "    \n",
    "    return dataframe\n",
    "    \n",
    "    \n",
    "def parse_mentioned_tickers(dataframe):\n",
    "    col='mentioned_tickers'\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),'(^\\[)|(\\])',''))\n",
    "    dataframe = dataframe.withColumn(col,F.explode(F.split(F.col(col),',')))\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),'\\.','-'))\n",
    "    dataframe = dataframe.withColumn(col, F.upper(F.col(col)))\n",
    "    return dataframe\n",
    "    \n",
    "def parse_date(dataframe):\n",
    "    \"\"\"date formaat: yyyy-MM-dd'T'HH:mm:ssZ\n",
    "    Example; 2020-05-29T12:50:59-0400\"\"\"\n",
    "    col = 'published_date'\n",
    "    dataframe = dataframe.withColumn(col,F.to_date(F.col(col),\"yyyy-MM-dd'T'HH:mm:ssZ\"))\n",
    "    return dataframe\n",
    "    \n",
    "def extract_news_writers(dataframe):\n",
    "    col='publisher'\n",
    "    \n",
    "    regexp_string = \"\"\"[A-Z][a-z]+ [A-z][a-z]+ The Motley Fool|[A-Z][a-z]+[ ][A-z][a-z]+ InvestorPlace|[A-Z][a-z]+[ ][A-Z].[ ][A-z][a-z]+ InvestorPlace|[A-Z][a-z]+[ ][A-Z].[ ][A-z][a-z]+ The Motley Fool\"\"\"\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),'Publisher *|Contributor *',''))\n",
    "    dataframe = (dataframe.withColumn('writer',F.when(F.col(col)\n",
    "                                                      .rlike(regexp_string),\n",
    "                                                      F.trim(F.regexp_replace(F.col(col),'The Motley Fool|InvestorPlace',''))).otherwise(F.lit(None).cast(StringType()))))\n",
    "    reuters_ds = dataframe.select(\"*\").where(F.col(col).contains('Reuters'))\n",
    "    reuters_ds = (reuters_ds.withColumn('writer',F.when(F.col(col)\n",
    "                                                      .rlike('[A-Z][a-z]+[ ][A-z][a-z]+ Reuters'),\n",
    "                                                      F.trim(F.regexp_replace(F.col(col),' Reuters ','~'))).otherwise(F.col('writer')).cast(StringType())))\n",
    "    #reuters_ds = reuters_ds.withColumn('writer',F.regexp_replace(F.col('writer'),'[s ]',''))\n",
    "    reuters_ds = reuters_ds.withColumn('writer',F.regexp_replace(F.col('writer'),' Reuter',''))\n",
    "    reuters_ds = reuters_ds.withColumn('writer',F.split(F.col('writer'),'~'))\n",
    "    reuters_ds = reuters_ds.withColumn('writer',F.explode(F.col('writer')))\n",
    "    dataframe = dataframe.union(reuters_ds)\n",
    "    dataframe = dataframe.withColumn(col,F.trim(F.col(col)))\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "def parse_delete_chars(dataframe,col):\n",
    "\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),'\\n',' '))\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),\"\\\\s+\",' '))\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),'\\,',''))\n",
    "    dataframe = dataframe.withColumn(col,F.trim(F.col(col)))\n",
    "    return dataframe\n",
    "\n",
    "def parse_contributor(dataframe):\n",
    "    col = 'publisher'\n",
    "    dataframe = dataframe.withColumn(col,F.regexp_replace(F.col(col),'Publisher *|Contributor *',''))\n",
    "    format_contributor = {'Motley Fool':'The Motley Fool','Reuters':'Reuters','InvestorPlace':'InvestorPlace'}\n",
    "    for key in format_contributor:\n",
    "        dataframe = dataframe.withColumn(col,F.when(F.col(col).contains(key),F.lit(format_contributor[key])).otherwise(F.col(col)))\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- contributor: string (nullable = true)\n",
      " |-- published_date: string (nullable = true)\n",
      " |-- mentioned_tickers: string (nullable = true)\n",
      "\n",
      "cols: 5 rows: 1668\n",
      "+--------------+------------------------------------------------+\n",
      "|published_date|title                                           |\n",
      "+--------------+------------------------------------------------+\n",
      "|2017-07-07    |The 10 Safest Blue-Chip Dividends on Wall Street|\n",
      "|2017-07-07    |The 10 Safest Blue-Chip Dividends on Wall Street|\n",
      "+--------------+------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "Nasdaq News\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- published_date: date (nullable = true)\n",
      " |-- mentioned_tickers: string (nullable = true)\n",
      "\n",
      "cols: 5 rows: 6194\n"
     ]
    }
   ],
   "source": [
    "parsed_nasdaq_news(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nasdaq News Cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@transform(spark,\n",
    "    parsed = Input('/nasdaq_news/parsed/nasdaq_news_parsed.parquet', spark),\n",
    "    metadata = Metadata('/nasdaq_news/clean/nasdaq_news_metadata_clean.csv', spark),\n",
    "    clean = Output('/nasdaq_news/clean/nasdaq_news_clean.parquet'),\n",
    "    clean_exception = Output('/nasdaq_news/exception/nasdaq_news_clean_exception.parquet')\n",
    ")\n",
    "def nasdaq_news_clean(spark, parsed, metadata, clean, clean_exception):\n",
    "    \n",
    "    schema = metadata()\n",
    "    \n",
    "    print(schema.fieldNames())\n",
    "\n",
    "    pipe = Pipeline(parsed)\n",
    "    pipe = (pipe\n",
    "            .show_dimensions()\n",
    "\n",
    "           )\n",
    "    pipe.dataframe.printSchema()\n",
    "   \n",
    "\n",
    "\n",
    "    validated_pipe = ValidatedPipeline(pipe, metadata)\n",
    "    validated_pipe = (validated_pipe\n",
    "                      #.add_validation(F.col('home_team_name') == 'Arsenal', 'column is null')\n",
    "                      .validate()\n",
    "                     )\n",
    "    \n",
    "\n",
    "    validated_pipe.write(clean, clean_exception)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['title', 'content', 'publisher', 'published_date', 'mentioned_tickers']\n",
      "cols: 5 rows: 6194\n",
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- published_date: date (nullable = true)\n",
      " |-- mentioned_tickers: string (nullable = true)\n",
      "\n",
      "Validated count: 6194\n",
      "Exception count: 0\n"
     ]
    }
   ],
   "source": [
    "nasdaq_news_clean(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
