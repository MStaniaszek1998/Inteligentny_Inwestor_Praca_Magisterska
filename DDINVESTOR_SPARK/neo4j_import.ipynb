{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = '/media/mateusz-destroyer/sdb3/dev_sandbox/dev_sandbox_neo4j_import'\n",
    "\n",
    "DDL_COMP_DETAILS = './data/company_details/ddl'\n",
    "DDL_NEWS_PRICE = './data/news/ddl'\n",
    "DDL_STOCK_PRICE = './data/stock_price/ddl'\n",
    "# DDL_PATH_matches_history = './data/matches_history/ddl'\n",
    "DDL_PATH_files = './data/_file_transforms'\n",
    "\n",
    "NODES_FILES = {\n",
    "    'Industry': [DDL_COMP_DETAILS, 'industry_ddl.csv'],\n",
    "    'Sector': [DDL_COMP_DETAILS, 'sector_ddl.csv'],\n",
    "    'City': [DDL_COMP_DETAILS, 'city_ddl.csv'],\n",
    "    'State': [DDL_COMP_DETAILS, 'state_ddl.csv'],\n",
    "    'Country': [DDL_COMP_DETAILS, 'country_ddl.csv'],\n",
    "    'Company': [DDL_COMP_DETAILS, 'comp_details_ddl.csv'],\n",
    "    'Shareholder': [DDL_COMP_DETAILS, 'shareholders_ddl.csv'],\n",
    "    'Publisher':[DDL_NEWS_PRICE, 'publisher_ddl.csv'],\n",
    "    'News':[DDL_NEWS_PRICE, 'news_ddl.csv'],\n",
    "    'Date':[DDL_NEWS_PRICE, 'date_ddl.csv'],\n",
    "    'Stock':[DDL_STOCK_PRICE, 'stock_ddl.csv'],\n",
    "    \n",
    "    'File': [DDL_PATH_files, 'files_ddl.csv'],\n",
    "    'Transform': [DDL_PATH_files, 'transforms_ddl.csv'],\n",
    "    'App': [DDL_PATH_files, 'apps_ddl.csv']\n",
    "}\n",
    "\n",
    "RELATIONS_FILES = {\n",
    "    'IN_INDUSTRY': [DDL_COMP_DETAILS, 'company_IN_INDUSTRY_industry_ddl.csv'],\n",
    "    'MEMBER_OF': [DDL_COMP_DETAILS, 'industry_MEMBER_OF_sector_ddl.csv'],\n",
    "    'LOCALIZED_IN': [DDL_COMP_DETAILS, 'company_LOCALIZED_IN_city_ddl.csv'],\n",
    "    'IS_IN': [DDL_COMP_DETAILS, 'city_IS_IN_state_ddl.csv'],\n",
    "    'IS_IN_2': [DDL_COMP_DETAILS, 'city_IS_IN_country_ddl.csv'],\n",
    "    'PART_OF': [DDL_COMP_DETAILS, 'state_PART_OF_country_ddl.csv'],\n",
    "    'HAS_SHARES_IN': [DDL_COMP_DETAILS, 'shareholder_HAS_SHARES_IN_company_ddl.csv'],\n",
    "    'IS_VALUED_FOR':[DDL_STOCK_PRICE, 'stock_IS_VALUED_FOR_company_ddl.csv'],\n",
    "    'PUBLISHES':[DDL_NEWS_PRICE, 'publisher_PUBLISHES_news_ddl.csv'],\n",
    "    'CONCERNS':[DDL_NEWS_PRICE, 'news_CONCERNS_company_ddl.csv'],\n",
    "    'IS_ISSUED_ON':[DDL_NEWS_PRICE, 'news_IS_ISSUED_ON_date_ddl.csv'],\n",
    "    'IS_VALUED_ON':[DDL_STOCK_PRICE, 'stock_IS_VALUED_ON_date_ddl.csv'],\n",
    "    \n",
    "    'INPUT': [DDL_PATH_files, 'file_INPUT_transform_ddl.csv'],\n",
    "    'OUTPUT': [DDL_PATH_files, 'file_OUTPUT_transform_ddl.csv'],\n",
    "    'METADATA': [DDL_PATH_files, 'file_METADATA_transform_ddl.csv'],\n",
    "    'STAGE_OF': [DDL_PATH_files, 'transform_STAGE_OF_app_ddl.csv']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IN_INDUSTRY': ['./data/company_details/ddl',\n",
       "  'company_IN_INDUSTRY_industry_ddl.csv'],\n",
       " 'MEMBER_OF': ['./data/company_details/ddl',\n",
       "  'industry_MEMBER_OF_sector_ddl.csv'],\n",
       " 'LOCALIZED_IN': ['./data/company_details/ddl',\n",
       "  'company_LOCALIZED_IN_city_ddl.csv'],\n",
       " 'IS_IN': ['./data/company_details/ddl', 'city_IS_IN_state_ddl.csv'],\n",
       " 'IS_IN_2': ['./data/company_details/ddl', 'city_IS_IN_country_ddl.csv'],\n",
       " 'PART_OF': ['./data/company_details/ddl', 'state_PART_OF_country_ddl.csv'],\n",
       " 'HAS_SHARES_IN': ['./data/company_details/ddl',\n",
       "  'shareholder_HAS_SHARES_IN_company_ddl.csv'],\n",
       " 'IS_VALUED_FOR': ['./data/stock_price/ddl',\n",
       "  'stock_IS_VALUED_FOR_company_ddl.csv'],\n",
       " 'PUBLISHES': ['./data/news/ddl', 'publisher_PUBLISHES_news_ddl.csv'],\n",
       " 'CONCERNS': ['./data/news/ddl', 'news_CONCERNS_company_ddl.csv'],\n",
       " 'IS_ISSUED_ON': ['./data/news/ddl', 'news_IS_ISSUED_ON_date_ddl.csv'],\n",
       " 'IS_VALUED_ON': ['./data/stock_price/ddl', 'stock_IS_VALUED_ON_date_ddl.csv'],\n",
       " 'INPUT': ['./data/_file_transforms', 'file_INPUT_transform_ddl.csv'],\n",
       " 'OUTPUT': ['./data/_file_transforms', 'file_OUTPUT_transform_ddl.csv'],\n",
       " 'METADATA': ['./data/_file_transforms', 'file_METADATA_transform_ddl.csv'],\n",
       " 'STAGE_OF': ['./data/_file_transforms', 'transform_STAGE_OF_app_ddl.csv']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RELATIONS_FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Industry': ['./data/company_details/ddl', 'industry_ddl.csv'],\n",
       " 'Sector': ['./data/company_details/ddl', 'sector_ddl.csv'],\n",
       " 'City': ['./data/company_details/ddl', 'city_ddl.csv'],\n",
       " 'State': ['./data/company_details/ddl', 'state_ddl.csv'],\n",
       " 'Country': ['./data/company_details/ddl', 'country_ddl.csv'],\n",
       " 'Company': ['./data/company_details/ddl', 'comp_details_ddl.csv'],\n",
       " 'Shareholder': ['./data/company_details/ddl', 'shareholders_ddl.csv'],\n",
       " 'Publisher': ['./data/news/ddl', 'publisher_ddl.csv'],\n",
       " 'News': ['./data/news/ddl', 'news_ddl.csv'],\n",
       " 'Date': ['./data/news/ddl', 'date_ddl.csv'],\n",
       " 'Stock': ['./data/stock_price/ddl', 'stock_ddl.csv'],\n",
       " 'File': ['./data/_file_transforms', 'files_ddl.csv'],\n",
       " 'Transform': ['./data/_file_transforms', 'transforms_ddl.csv'],\n",
       " 'App': ['./data/_file_transforms', 'apps_ddl.csv']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NODES_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in NODES_FILES:\n",
    "\n",
    "    original = glob(f'{NODES_FILES[key][0]}/{NODES_FILES[key][1]}/*.csv')[0]\n",
    "   \n",
    "    destination = f'{DB_PATH}/{NODES_FILES[key][1]}'\n",
    "    shutil.copyfile(original, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN_INDUSTRY\n",
      "MEMBER_OF\n",
      "LOCALIZED_IN\n",
      "IS_IN\n",
      "IS_IN_2\n",
      "PART_OF\n",
      "HAS_SHARES_IN\n",
      "IS_VALUED_FOR\n",
      "PUBLISHES\n",
      "CONCERNS\n",
      "IS_ISSUED_ON\n",
      "IS_VALUED_ON\n",
      "INPUT\n",
      "OUTPUT\n",
      "METADATA\n",
      "STAGE_OF\n"
     ]
    }
   ],
   "source": [
    "for key in RELATIONS_FILES:\n",
    "    print(key)\n",
    "    original = glob(f'{RELATIONS_FILES[key][0]}/{RELATIONS_FILES[key][1]}/*.csv')[0]\n",
    "    destination = f'{DB_PATH}/{RELATIONS_FILES[key][1]}'\n",
    "    shutil.copyfile(original, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "class QueryBuilder:\n",
    "    def __init__(self, DB_PATH, class_name, file_name):\n",
    "        self._DB_PATH = DB_PATH\n",
    "        self._class_name = class_name\n",
    "        self._file_name = file_name\n",
    "        \n",
    "        self._load_fieldnames()\n",
    "        \n",
    "    def _load_fieldnames(self):\n",
    "        path = f'{self._DB_PATH}/{self._file_name}'\n",
    "        with open(path, 'r') as file:\n",
    "            reader = csv.DictReader(file,delimiter=',')\n",
    "            self._fieldnames = reader.fieldnames\n",
    "    \n",
    "    def create_node(self):\n",
    "        \"\"\" e.g.\n",
    "        LOAD CSV WITH HEADERS FROM 'file:///cities_ddl.csv' AS row\n",
    "        MERGE (c:City {city_id: row.city_id, city_name: row.city_name})\n",
    "        \"\"\"\n",
    "        key = self._class_name\n",
    "        file_name = self._file_name\n",
    "        fieldnames = self._fieldnames\n",
    "        \n",
    "        query = f\"LOAD CSV WITH HEADERS FROM 'file:///{file_name}' AS row \"\n",
    "        query += f\"MERGE (c:{key} \" + \"{\"\n",
    "        for field in fieldnames:\n",
    "            query += f\"{field}: row.{field}, \"\n",
    "        query = query[:-2]\n",
    "        query += \"})\"\n",
    "        \n",
    "        return query\n",
    "        \n",
    "    def create_index(self):\n",
    "        key = self._class_name\n",
    "        fieldname = self._fieldnames[0]\n",
    "        \n",
    "        query = f\"CREATE INDEX ON :{key}({fieldname})\"\n",
    "        \n",
    "        return query\n",
    "    \n",
    "    def create_relation(self):\n",
    "        \"\"\" e.g.\n",
    "        LOAD CSV WITH HEADERS FROM 'file:///city_LOCATED_IN_country_ddl.csv' AS row\n",
    "        MATCH (c1:City {city_id: row.city_id}), (c2:Country {country_id: row.country_id})\n",
    "        CREATE (c1)-[:LOCATED_IN]->(c2)\n",
    "        \"\"\"\n",
    "\n",
    "        relation = self._class_name\n",
    "        file_name = self._file_name\n",
    "        src_id = self._fieldnames[0]\n",
    "        src = src_id[:src_id.find('_')].capitalize()\n",
    "        dest_id = self._fieldnames[1]\n",
    "        dest = dest_id[:dest_id.find('_')].capitalize()\n",
    "        \n",
    "        query = f\"LOAD CSV WITH HEADERS FROM 'file:///{file_name}' AS row \"\n",
    "        query += f\"MATCH (c1:{src}\" + \"{\" + f\"{src_id}: row.{src_id}\" + \"}), \"\n",
    "        query += f\"(c2:{dest} \" + \"{\" + f\"{dest_id}: row.{dest_id}\" + \"}) \"\n",
    "        query += f\"CREATE (c1)-[:{relation}]->(c2)\"\n",
    "        \n",
    "        return query\n",
    "    \n",
    "    def drop_index(self):\n",
    "        key = self._class_name\n",
    "        fieldname = self._fieldnames[0]\n",
    "        \n",
    "        query = f\"DROP INDEX ON :{key}({fieldname})\"\n",
    "        \n",
    "        return query\n",
    "    \n",
    "    @staticmethod\n",
    "    def drop_relations():\n",
    "        return \"MATCH (n)-[r]-() DELETE r\"\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_nodes():\n",
    "        return \"MATCH (n) DELETE n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neo4jConnector:\n",
    "\n",
    "    def __init__(self, uri, user, password):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "\n",
    "    def close(self):\n",
    "        self.driver.close()\n",
    "            \n",
    "    def execute_query(self, query):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.write_transaction(self._query, query)\n",
    "            print(result)\n",
    "            \n",
    "    @staticmethod\n",
    "    def _query(tx, query):\n",
    "        result = tx.run(query)\n",
    "        return result.single()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def queries_create():\n",
    "    queries = []\n",
    "    for key in NODES_FILES:\n",
    "        qb = QueryBuilder(DB_PATH, key, NODES_FILES[key][1])\n",
    "        queries.append(qb.create_node())\n",
    "    for key in RELATIONS_FILES:\n",
    "        name=key\n",
    "        if key == 'IS_IN_2':\n",
    "            name='IS_IN'\n",
    "        qb = QueryBuilder(DB_PATH, name, RELATIONS_FILES[key][1])\n",
    "        queries.append(qb.create_relation())\n",
    "    return queries\n",
    "\n",
    "def queries_drop():\n",
    "    queries = []\n",
    "    for key in NODES_FILES:\n",
    "        qb = QueryBuilder(DB_PATH, key, NODES_FILES[key][1])\n",
    "        #queries.append(qb.drop_index())\n",
    "    queries.append(qb.drop_relations())\n",
    "    queries.append(qb.drop_nodes())\n",
    "    return queries\n",
    "\n",
    "def refactor_graph():\n",
    "    queries = []\n",
    "    queries.append(\"\"\"\n",
    "    MATCH (n:File) \n",
    "    WHERE n.type='Dataset' \n",
    "    WITH n\n",
    "    CALL apoc.create.addLabels(n, ['Dataset'])\n",
    "    YIELD node\n",
    "    RETURN count(node)\n",
    "    \"\"\")\n",
    "    \n",
    "    queries.append(\"\"\"\n",
    "    MATCH (n:File) \n",
    "    WHERE n.type='Exceptions' \n",
    "    WITH n\n",
    "    CALL apoc.create.addLabels(n, ['Exceptions'])\n",
    "    YIELD node\n",
    "    RETURN count(node)\n",
    "    \"\"\")\n",
    "    \n",
    "    queries.append(\"\"\"\n",
    "    MATCH (n:File) \n",
    "    WHERE n.type='Schema' \n",
    "    WITH n\n",
    "    CALL apoc.create.addLabels(n, ['Schema'])\n",
    "    YIELD node\n",
    "    RETURN count(node)\n",
    "    \"\"\")\n",
    "    \n",
    "    queries.append(\"\"\"\n",
    "    MATCH (n1:App)-[r1:STAGE_OF]-(n2:Transform)-[r2:OUTPUT]-(n3:Dataset)-[r3:INPUT]-(n4:Transform)-[r4:STAGE_OF]-(n5:App)\n",
    "    WHERE n1 <> n5\n",
    "    WITH n1, n5\n",
    "    CREATE (n1)-[:NEXT]->(n5)\n",
    "    \"\"\")\n",
    "    \n",
    "    return queries\n",
    "\n",
    "def query(queries):\n",
    "    neo4j = Neo4jConnector(\"bolt://localhost:7687\", \"neo4j\", \"passwd\")\n",
    "    for query in queries():\n",
    "        neo4j.execute_query(query)\n",
    "    neo4j.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "<Record count(node)=48>\n",
      "<Record count(node)=11>\n",
      "<Record count(node)=41>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "query(queries_drop)\n",
    "query(queries_create)\n",
    "query(refactor_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
